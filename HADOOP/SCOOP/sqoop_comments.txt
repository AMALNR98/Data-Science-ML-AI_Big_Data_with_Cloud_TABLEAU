


1. list-databases

	syntax:
		sqoop list-databases --connect jdbc:mysql://ipaddress/ --username mysql_username --password mysql_psd

		-- 	: arguments
		jdbe 	: java database connectivity
		

	eg : 
		sqoop list-databases --connect jdbc:mysql://localhost/ --username root --password Password@123


2. list tables inside database

	syntax:
		sqoop list-tables --connect jdbc:mysql://ipaddress/database_name --username mysql_username --passowrd mysql_psd

	eg:
		sqoop list-tables --connect jdbc:mysql://localhost/luminar --username root --password Password@123

3. import database into hdfs
	
	when we import database to hdfs, the input is table, then the imported table in stored in hdfs is as text file

	syntax:

		sqoop import --connect jdbc:mysql://localhost/dbname --table table_name --username mysql_username --passowrd psd --m 1

			--m : mapreduing algorithem execution
			1   : replication factor

	eg:
		sqoop import --connect jdbc:mysql://localhost/luminar --table batches --username root --password Password@123 --m 1

	we cannot import same table again, for that we have to rename table


4. import all table to hdfs

	syntax:

		sqoop import-all-tables --connect jdbc:mysql://localhost/dbname --username user_name --password paswrd --m 1

	(for delete tables delete form hdfs by hadoop fs -rm -R......)

	eg:
		sqoop import-all-tables --connect jdbc:mysql://localhost/luminar --username root --password Password@123 --m 1


5. exclude-one table 

	sqoop import-all-tables --connect jdbc:mysql://localhost/dbname --exclude-tables table_name --username user_name --password pswrd --m 1
		

	for multiple rows

		sqoop import-all-tables --connect jdbc:mysql://localhost/dbname --exclude-tables tblname1,tblname2, tblname3 --username root --password passwprd -m 1





6. import 1 table into specific location

	syntax:

		sqoop import --connect jdbc:mysql://ipaddress/dbname --table table_name --username user_name password Password@123 --m 1 --target-dir /path/new_directory_name 

	eg:
		sqoop import --connect jdbc:mysql://localhost/luminar --table student --username root --password Password@123 --m 1 --target-dir /system/luminar_data


7. for import all datas to an specific location

	syntax:

		sqoop import-all-tables --connect jdbc:mysql://ipaddress/dbname --username username --password password --m 1 --warehouse-dir /path


8. import subset of data

	only wanted data wiil import by conditions

	syntax:

		sqoop import --connect jbdc:mysql://localhost/dbname --table table_name --where "condition" --username user_name --password pass_word --m 1 --taget-dir /path


	eg:
	1)	
	sqoop import --connect jdbc:mysql://localhost/luminar --table student --where "age>22" --username root --password Password@123 --m 1 --target-dir /workout/result1

	2)
	sqoop import --connect jdbc:mysql://localhost/luminar --table student --where "prof='bigdat'" --username root --password Password@123 --m 1 --target-dir /workout/result2


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


9. export 

	input will text file and output will be table
	the text file from hdfs will exported to mysql
	so, for that we have to create tabel in mysql

	syntax:

		sqoop export --connect jdbc:mysql://localhost/dbname --table table_name --usename user_name --password pass_word --export-dir /hdfs_file_path


	eg:
		create table in mysql
		create table sample1_data(id1 int,id2 int, id3 int,id4 int);

		then
		sqoop export --connect jdbc:mysql://localhost/luminar --table sample1 --username root --password Password@123 --export-dir /workout/result1
